#+html_head: <link rel="stylesheet" type="text/css" href="org.css"/>
#+title: Cuboids Manifesto
#+options: toc:nil
#+options: html-postamble:nil

| Author  | [[http://tigue.com][John Tigue]]   |
| Version | 2020-11-01-1 |
| License | CC0 1.0      |

* Abstract
  
This document proposes refresh modifications and novel extentions to
the bossDB open source codebase. The envisioned platform has been
given the working title of Cuboids.

The initial goal is an architectural update leveraging the latest AWS
serverless innovations in order to simplify deployment and maintenance
of the existing system, while maintaining the existing bossDB surface
APIs. The subsequent goal is to build out Cuboids with the bossDB
database repository as the backend.

The resulting Cuboids platform is to be a "whole product" which
recapitulates the multi-system architecture of the MICrONS project but
with all tasks -- storage, analysis, visualization, etcetera -- performable
within a Cuboids instance. The most significant process to be moved
into the service is reconstruction of neurons via image recognition
machine learning algorithms.

#+attr_html: :width 80%
[[./images/logos/cuboids_lettermark_bw.png]]

#+TOC: headlines 3h

* Introduction

The [[https://bossdb.org/][bossDB]] is a [[https://en.wikipedia.org/wiki/Volume_rendering][volumetric]] database capable of storing petabytes of data
resulting from microscopic imaging of neurological tissue. It also known
colloquially as "the Boss" and in this document both terms are
interchangable. Its initial development was funded via grants from
[[https://www.iarpa.gov/][IARPA]] under [[https://www.iarpa.gov/index.php/research-programs/microns][the MICrONS project]]. The resulting source code -- spanning
multiple repositories -- is available under the [[https://www.apache.org/licenses/LICENSE-2.0][Apache
2.0]] open source license.

The modified bossDB codebase proposed herein is designed to be the
repository component of a platform which has been given the working
title of Cuboids. Cuboids builds atop existing work by doubling down
on the current AWS lock-in of bossDB, in the interests of simplifying
the architecture in order to make it easier to administer. This part of the proposal
is simply "better, faster, cheaper" thinking which does not change the
high-level feature set of the repository.

Beyond the aforementioned architectural refresh, Cuboids aims to be
more than just a repository. Given the current architecture of the
Boss, image analysis has to be performed by separate external systems,
requiring the transfer of mountains of data. Cuboids builds on the
previous bossDB work such that analysis of the data residing in a
bossDB repository can performed close to the data. Doing so enables
Cuboids to be more of a "whole product" for microscopy workflows
rather than simply a repository accessed by external analysis tools.

The original bossDB codebase evidences a valid and shrewd
architectural style which values vendor neutral open source. Yet to
deal with the sporatic volume and velocity of data being throw off by
electron microscopes, an AWS serverless engine was adopted. This
worked well but resulted in a mixed architectural style which is more
complex than currently necessary. In 2015, when work on the Boss was
started, a purely serverless architectures simply could not be
build. Cuboids aims to resolve the complexity by going all-in on AWS
lock-in by jettisoning any components which can be replaced by
equivalent fully managed AWS services.

Peta-scale datasets are unlikely to ever migrate from where they are
initially reposited.  Recognizing this and the fact that the existing
AWS-only codebase is currently managing petabytes of data in AWS, this
manifesto accepts the reality of single vendor lock-in with regards to
cloud provider platform and so drinks deeply from the AWS serverless
Kool-Aid pitcher by moving towards less servers and more fully managed
services.

#+attr_html: :width 25%
[[./images/aws_pitcher.png]]

* Existing high level architecture of the Boss


 The technical architecture of the data system of the MICrONS project
 reflects the multi-team nature of the MICrONS project for which the
 Boss was created. 

 #+attr_html: :width 100%
 [[./images/microns_phase_2.jpg]]

  
In its current form the Boss architecture can be considered a hybrid
of two styles. The foundational frame consists of non-serverless,
platform neutral, open source machinery. Within that frame is
a turbo boosted engine of serverless tech. This choice was made
for valid reasons back in 2015 and time has shown the resulting
codebase has served its original purpose well.

Note: the hybrid nature of the Boss architecture is not a result of
the multi-team social structure. On the other hand, the fact that the
original Boss does not do reconstruction image recognition is indeed a
reflection of the social structure. It can also be seen as a wise
limitation of scope of development of the initial Boss.

The following diagram is taken from the original bossDB pre-print. The
yellow box has been added to highlight the serverless core of the
architecture. Sundry adopted AWS services are enumerated in
the bottom boxed region. The rest is the non-serverless, platform
neutral machinery.

#+attr_html: :width 75%
[[./images/bossdb_serverless_highlighted.png]]

The core engine of BossDB features the usual suspects of AWS severless
technology: Lambda, SQS, DynamoDB, Step Functions, etc. Arguably,
the Read/Write Cache is not serverless but it is part of the core engine,
enabling high performance. The rest of the components are proven
non-serverless, open source technologies: Bastion, Vault, Keycloak,
etc.

The JHU/APL team already had a lot of open source based coding
experience before the MICrONS project. As such they leveraged that
knowledge while working on BossDB. For example, they deployed various
code repositories for storing secrets, managing single sign-on,
handling RESTful API requests, etc. None of that is particularly
interesting, domain specific machinery but the functionality they
provide amounts to table stakes for a modern, secure, and mature
application. It made sense to reapply what they already knew how to
use.

In the arch diagram that old-school stuff can be grouped into three sub-system, here in red:
- The upper left red zone is the REST interface
- The Single Sign-on subsystem is in the upper right red zone
- The lower reg zone can be replace with AWS Secrets Manager

#+attr_html: :width 75%
[[./images/bossdb_delta_components.png]]

From an external perspective, the resulting architectural structure is
still sound. Cuboids will maintain the existing Boss HTTP APIs to the
repository component and only modify its internal structure. Thereby
Cuboids will be able to interface with multiple bossDB repositories,
including the one wherein the MICrONS data resides. For example, labs
could cache subsets of the MICrONS data for private analysis and
annotation.

* Realtechnik of cloud architecting

Significant but non-core parts of the bossDB codebase are from a
pre-cloud, platform neutral, open source culture. Vendor neutrality is
a good thing but Cuboids consciously jettisons that feature in the
interests of accellerating innovation via improved developer velocity
and reduced devops workload. Any perfectly good open-source component
of the Boss replaced with an equivalent AWS fully managed service
means less deployment and management hassles.

In the Swift programming community there has arisen a type of document
known as a "[[https://www.youtube.com/watch?v=s1AiBi5gf1s][manifesto]]." These serve the purpose of introducing concepts
which are bigger than a single, small focused proposal. This document
follows that lighthearted nomenclature, in order to highlight that
there is a [[https://www.ribbonfarm.com/2012/08/16/realtechnik-nausea-and-technological-longing/][realtechnik]] "philosophy" behind this proposal, one which
is driven by two assumptions:
- The original Boss codebase can only be deployed on AWS
- Very large datasets (in particular, the MICrONS data) are rather immobile
  
As to the former assumption, normally it is ideal if open source code
is platform vendor neutral.  Yet failing the ideal there are still
benefits to the open source way, for example, innovation shared
throughout a community of users. The Boss, given its AWS serverless
engine, is very much not vendor neutral.  For example, the Boss makes
use of AWS Step Functions. Unfortunately there is currently no
equivalent abstraction available which works on other cloud platforms
(which seems odd but c'est la vie). Given the AWS technologies already
adopted in the bossDB codebase, Cuboids accepts and runs with the
reality of AWS lock-in, probably in perpetuity.

[ *TODO: use or toss* It is arguably a bit perverse for open source
to be tuned up just for a single commercial cloud platform, but the
hypothesis herein is that by doing so it will make it much easier for
other organizations to deploy BossDB, thereby speeding up the
diffusion of innovation. Ideally the other cloud providers would have
equivalent tech to those parts of AWS used in the BossDB refresh, but
sadly that is not the case in mid-2020.]
 
The latter assumption acknowledges the inertia of peta-scale
datasets. The MICrONS data is already in AWS S3. Other smaller
datasets are also accreting in Boss deploys on AWS. So code
which analyses these datasets yet only runs on AWS is not a major
negative. Of course, this too is gradually leading to more AWS lock
in. Other cloud vendors are missing out on an emerging industry
sector. Obviously it is not the biggest sector in terms of users but this
is heading towards exo-scale datasets which is not insignificant.

Datasets on such a scale as that of the MICrONS data form a
gravitational well inducing system architectures wherein data
processing happens as close to the data as possible; it is desirable
to minimise massive data trasfers. Although the existing bossDB APIs
can be used to fetch raw data for analysis on systems external to the
Boss, Cuboids intends to extend the Boss platform such that data
analysis can be performed within the system. Quoting Francis Bacon:
#+BEGIN_QUOTE
Mahomet cald the Hill to come to him. And when the Hill stood still,
he was neuer a whit abashed, but said; If the Hill will not come to
Mahomet, Mahomet wil go to the hil. [sic]
#+END_QUOTE

#+attr_html: :width 400px
[[./images/mohammed_and_the_mountain.jpg]]

The two above assumptions drive the logic of this document. This
proposal argues to dive headlong down the slippery slope of AWS
lock-in. This recommended direction may seem counterintuitive and even
distasteful given the platform vendor neutral, open source ecosystem
out of which the Boss grew. Nonetheless, although the lead that AWS
enjoys over the other cloud platform vendors [[https://cloudwars.co/amazon/inside-amazon-aws-no-longer-jeff-bezos-growth-engine/][is slipping]], it does not
appear that a cross-platform serverless version of bossDB is possible
at this time, given the state of those offerings competing with AWS
(e.g. a lack of an AWS Step Functions equivalent for Google Cloud
Platform).

Therefore, it is argued herein that the mixed architecture is
retarding the [[https://en.wikipedia.org/wiki/Diffusion_of_innovations][diffusion of innovation]], especially with regards to that
theory's criteria of "complexity" and "trialability." So, perhaps we
should just accept that this codebase will always be locked in to AWS
and drink their Kool Aid in order to lighten the load. 

As a reality check on this AWS serverless enthusiasm, there is a
decent 2020-10 article, [[https://www.infoq.com/articles/serverless-stalled/][Why the Serverless Revolution Has Stalled]],
which enumerates situations where serverless is not yet living up to
its promise. The Boss as a use case of serverless technology actually
passes almost all the checkpoints enumerated in that article: for
example, it is greenfield, all the code is written in Python (i.e. a
language well supported by AWS Lambda), and the entire app was
explicitly designed to run on a cloud platform. The single concern
raised which the Boss is guilty of vendor lock-in but as argued
herein, that is acknowledged and accepted.

The Cuboids variant of the codebase will remain open source,
volunarily maintaining the Apache 2.0 license.  Yet the code will be
very locked to AWS as the vendor, which is a rather ironic form of
open source.

* Architectural updates

The first stage of Cuboids development is to be an architectural
refresh of the existing Boss codebase, which is the topic of this
section. 

Actually, the initial development work will be to simply stand up a
Boss instance using the existing codebase. This document was written
after simply reading the code, documentation, and pre-prints; various
assumptions need to be validated in a hands-on context. Surely the
deployment experience will cause refinements to what is proposed in
this manifesto.

The deployment experience will be documented. Perhaps that will prove
useful to other adminstrators of Boss deploys.

** Overview

[ *TODO:* This section currently is far enough along to where the
logic can be followed but there is a lot of repetition. It needs to be
made terser.]
   
The architectural refresh is motivated by abstract goals and those are
reified as specific coding project. The abstract goals are to effect
the following changes.

| Before                     | After                         |
|----------------------------+-------------------------------|
| Hybrid architecture        | Serverless first architecture |
| Some self-managed services | More fully managed services   |
| Complex deployment         | Simplified deployment         |
| JHU/APL's [[https://github.com/jhuapl-boss/heaviside][heaviside]]        | AWS CDK                       |

The main goal of the architectural refresh is to reduce the complexity
resulting from the hybrid architecture by moving towards a
serverless-first architecture. 

[ *TODO:* cull?] This is to be accomplished by adopting into the
codebase more AWS technologies -- some of which simply did not exist
in 2015 when work started on the codebase. Replacing the
non-serverless machinery with equivalent AWS services will reduce the
complexity of deploying and maintaining a Boss instance.

The bossDB codebase was [[https://github.com/jhuapl-boss/boss/graphs/contributors][started in 2015]], which was early days for AWS
serverless, nevermind using such young technology to scale to
petabytes of data. This necessitated building out various
[[https://jeremybower.com/articles/undifferentiated-heavy-lifting-2-0.html]["undifferentiated heavy lifting"]] support machinery in order to get on
with the task of building a petascale volumetric spatial database.

In the interim, AWS has gotten around to providing fully managed
services such as API Gateway, Cognito, and AWS Secrets Manager. They
have also built out SDKs such as AWS CDK, the absense of which drove
JHU/APL to create heaviside. Simply keeping the current serverless
core architecture but rewriting those components which could be
replaced with equivalent AWS service would make bossDB easier to
deploy and maintain.

Note that the goals include *not* significantly modifying the features
of the Boss repository. Any distinctly novel functionality to be
introduced in Cuboids which is not present in the Boss codebase will
be constructed outside the Boss repository component. (Envisioned
novelties are enumerated in later sections.) 

The serverless core will remain fundamental the same. The most
significant change to the core will be its interface to the auth and
audit system which is to be based on AWS Cognito.
 
Any non-serverless components which can be replaced with AWS managed
services will be jettisoned.

[ *TODO:* This diagram is to be enhanced with a tag for each red block indicating what it is to be replaced with.]

#+attr_html: :width 40%
[[./images/bossdb_delta_components.png]]
  
In the above diagram, the three parts of the architecture to be refurbished are:
- The RESTful interface machinery: to be handled by Amazon API Gateway
- The Single-Sign On (SSO) machinery: to be migrated AWS Cognito
- The secrets keeping machinery: to be replaces with AWS Secrets Manager

These sub-systems to be modified are simply necessary
support infrastructure, not to the core serverless engine of the
spatial database which is to remain essentially unchanged.

The three changes seek to minimize management by adopting equivalent
fully managed AWS services.

To be clear, the code to be replaced is good code but require
management and related infrastructure.
- Proven platform independent, scalable open source.
- It's solid pre-serverless tech

Features of the parts to be update
- Undifferentiated, off-the-shelf app infrastructure, not domain specific
- Quality, proven, platform-independent open source
- Not serverless
- Requiring server management

Features of the parts being kept essentially as they are
- AWS serverless. The core engine of bossDB
- Bespoke code for dealing with cuboids
- Domain specific
- AWS only open source
  
In the following before-and-after juxtaposition diagram, the image on
the left is a repeat of a diagram from earlier in this
document. Notice that the yellow backgrounded serverless core remains
the same.

#+attr_html: :width 100%
[[./images/arch_before_and_after.png]]


** RESTful interface machinery

[ *TODO:* API Gateway was [[https://aws.amazon.com/about-aws/whats-new/2015/07/introducing-amazon-api-gateway/][introduced in 2015-07]]. The repo for the boss
REST API was [[https://github.com/jhuapl-boss/boss/graphs/contributors][started in 2015-11]]. So not sure why it was not adopted. ]

Maintain backwards compatibility of the interface. This is purely
about simplyfying the machinery which implements the interface, not
about change the user experience of the interface. There should be a
test suite which ensures this; one test client that can work with both
the Boss and Cuboids simply by changing the end-point URL.

API Gateway's main purpose is to provide HTTP interfaces to AWS
Lambda. Since the core is Lambda-based serverless it is only natural
to use API Gateway. This is an instance of an undifferentiated
component which the Boss needed but for which there was no available
AWS service at the time of initial development of the Boss. 

API Gateway
- The upper left red zone can be replaced by API Gateway etc.
- [ ] What's in that RDS instance
  - "data model objects & permissions"
  - Sounds pretty scheme-esque
  - Aurora Serverless? (if even need a SQL machine)

** Single sign-on
- Moving to Cognito will simplify per tenant billing and logging.
- The upper right red zone can be replaced by Cognito
  #+begin_quote
  We use the open source software package Keycloak as an identity
  provider to manage users and roles. We created a Django OpenID
  Connect plugin to simplify the integration of services with the SSO
  provider.
  ...

  Our identity provider server intentionally runs in- dependently from
  the rest of bossDB system, forc- ing the bossDB API to authenticate
  just like any other SSO integrated tool or application, and making
  fu- ture federation with other data archives or authenti- cation
  systems easy.

  The Keycloak server is deployed in an auto-scaling group that sits
  behind an Elastic Load Balancer.
  #+end_quote

- Want to be able to have a high res billing system.
  - Cognito makes that easier
  - Want a University to deploy yet be able to bill distinct departments
  - Want multi-tenant SaaS, which is similar to the university and departments

- Consider a security interface or delegator
  - core serverless engine would only talk to the interface/delegator
  - then security could be config to a Cognito provider
  - Or maybe even a dummy provider i.e. let anybody, do anything.
    - simpler management :)

- Perhaps there is already a bridge between Cogniton and whatever they are using for SSO
  - this way could still respect whatever they have going on but core code only talks Cognito
  - i.e. the pluggable interface IS Cognito.
    - So, dummy security would be a Cognito provider that says "whatevs" to anything.

** Secrets
- The lower reg zone can be replace with AWS Secrets Manager
- Existing
  - Vault servers are Secrets which store their info in Consul
  - Consul Servers are for key/value store

** Infrastructure as code tooling
The forth main subproject is to replace heaviside with AWS CDK Python code.
- Want to write bossDB based programs/experiments which are StepFunctions
- Say, convolving some Vaa3D plug-ins over a volume
- Say, countless (2,2,2) => (1,1,1) fast pyramid builder
- Dont want to do that on heaviside.
- So, replace all existing heaviside with equivalent CDK code, then go forward on AWS tech
  - much bigger community than heaviside-users, better community support

Also related is how they are generated. It is proposed to drop
Heaviside and adopt AWS CDK in stead.

Additionally, there is a non-service technology of the Boss which will
be replace with equivalent AWS tecnology: Heaviside, which will be
replaced with AWS CDK based code.

Heaviside is another example of JHU/APL (specifically, Derek Pryor)
inventing tech needed for sanely building AWS serverless applications.
Eventually AWS got around to releasing their own equivalent
technology, AWS CDK.  

So, a decision presents itself: continue to build the core high level
logic of Boss internal programs atop a one-off tooling library by a
small team or take the hit of rewriting the existing
heaviside code as AWS CDK code in order to reap the benefits of
working with a more mature implementation of a tech which is currently
diffused throughout a much larger community of developers.

AWS CDK is available for multiple programming languages. The Boss is
written in Python so it is only logical to use the Python AWS CDK.

* Architectural extensions
** Additional services as Step Functions based programs

- [[https://aws.amazon.com/blogs/compute/implementing-serverless-manual-approval-steps-in-aws-step-functions-and-amazon-api-gateway/][Implementing Serverless Manual Approval Steps in AWS Step Functions and Amazon API Gateway]]
- [[https://aws.amazon.com/about-aws/whats-new/2017/02/amazon-api-gateway-integration-with-aws-step-functions/][Amazon API Gateway Integration with AWS Step Functions]]
- [[https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-api-gateway.html][Creating a Step Functions API Using API Gateway]]  

This is what would make for a serverless first architecture. The state
that bridges both serverless and non-serverless process is maintained
in a Step Function.

Deconvolution is a another Step Functions based service.

So, say some novel is to be added, say cuboid segmentation. To the
outside world the service will manifest as new methods added to the
REST APIs. Inside AWS, The HTTP messaages containing Boss REST
requests are handled by AWS API Gateway (APIGW) which initiates a step
function instance to run a job. So states will be lambdas; some states
might be long runing Activities, an EC2 instance which runs chunkflow
processes. 

Chuckflow is a job systems for processing cuboids of data where DCNNs
are run over small volumes (sub-cuboids) to perform ML based volume
segmentation to individual neurons etc. There are masters which
initiate jobs and there are workers who each do their little task. The
workers and masters could be any machines but are normally EC2
instances. At its core, their interaction is orchesrated by an SQS queue.

The workers could easily be Lambdas. That's when it becomes hybrid but
not in a serverless-first fashion. Next would be to wrap the existing
chuckflow master as a Step Funtions activity. Still not
serverless-first but could be a component in a StepFunction. So
experiment first with Lambda chunkflow workers, then if that goes well
figure out how to take the master code and shoehorn that into Lamba
somehow. That would be the full serverless implementation achieved in
stages.

Cuboids could also participate in old-school chunkflow systems. This
could be simply as Lambdas deployed to work with a stock chunkflow
system. Another option, Cuboids would be a worker in the main chunkflow system
and would delegate internally to Lambdas in an internal SQS doing the
same thing as chunkflow, or just passing through to individual Lambdas is small enough?]

This chuckflow example is used because it illustrates how Step
Functions can involve both Lamba and EC2 instances. That's why it's
worth implement services as Step Functions. Step Functions Activities
(i.e. the EC2 instances) are the escape valve override mechanism for
processes that cannot be made to work under the limitations of AWS
serverless e.g. Lambda's runtime limit of 15 minutes. The Step
Functions programs that treat Lambdas and Activities as equivalents
(i.e. just state nodes in the main state machine) is the
serverless-first way to have a hybrid architecture. Say, some CNN
training needs to be done and the data to train on is in a Boss
repository. By framing task as a Step Function, both Lambda-base and
EC2-based servers can be mixed. [ *TODO:* Is this the best example?
Why would one want to do that?  Ingest and train? ]
   
As argued above, is would be desirable for the compute of analysis to
happen close to the data. Ideally that would happen within the same
VPN, but simply between AWS VPNs is good enough.
   
This section clarifies the distinction between the surface APIs of the
Boss -- which are the HTTP API interface through which external
programs interact with the Boss -- and the internal service component
APIs upon which can be built programs that run within the Boss.
   
Ergo, the compute of work of purely digital analysis and scientific
experiments should be performed within the same VPC as the Boss
repository wherein the data to be analyzed resides.  The base
framework for such programs already exists within the Boss codebase in
the form of the AWS Step Functions already written in the codebase.
For example, the downsampling (Kleissa Hider 2017, Section 2.3.7):

#+begin_quote
To allow users to quickly assess, process, and interact with their
data, we need to iteratively build a resolution hierarchy for each
dataset by downsampling the source data. This is a workflow that is
run infrequently and on-demand, and needs to scale from gigabytes to
petabytes of data. We developed a serverless architecture built on AWS
Step Functions to manage failures and track process state. AWS Lambda
is used to perform the underlying image processing in an
embarrassingly parallel, scalable fashion. This approach allows us to
minimize resource costs while scaling on-demand in a fully-automated
paradigm
#+end_quote

Step Functions *are* programs -- programs that just so happen to have
explicitly defined state machines. (Step Functions bring state to the
innately stateless Lambdas.)  The states, Lambdas and Activities, are
the program modules which get assembled into a Step Functions based
program.  The Downsampler is the poster childe program written atop
the Boss platform.

Cuboids will continue to build more Step Functions based programs that
run within the platform. Neuron reconstruction will be the first one.

(Footnote: although AWS Step Functions are an AWS only service, it is
clear that the other cloud providers will offer equivalent
services. It may well be that there will be an open source equivalent
which can run on multiple cloud platforms, rather than being a fully
manage service. The obvious place for that is [[http://serverless.com][The Serverless
Framework]]. If multiple proprietary service arise, a thin abstraction
around them would suffice. This is core cloud architecture tech
begging for a vendor neutral implementation. It would be foundational
for multi-cloud solutions. Step Functions based programs are composed
of Lambdas and Activities, the innately stateless states in a
(stateful) Step Functions based program. They can be mentally modeled
as HTTP API'd services. There is nothing AWS specific about this
model. It can become Multi-cloud FOSS. So, ironically by proceeding
forward with Step Function, Cuboids may well be planning ahead to
remove the vendor lock in. But this is long term speculation. It does
not have to happen and for now is a digression.)



** Lambda layers for image processing Python libraries
In the case of the Boss, the raw image data resides in AWS S3 and is
indexed in DynamoDB. In 2015 Lambda could not accommodate code
packages of a size that would result from including the machine
learning tools, say, scikit-learn. This is another valid reason why image
processing was performed external to the Boss. Currently though with
things like Lambda layers and TensorFlow Light it can be done.
   
[[https://medium.com/@adhorn/getting-started-with-aws-lambda-layers-for-python-6e10b1f9a5d][Getting started with AWS Lambda Layers for Python]]

This brings chunkflow and tensorflow into Cuboids

Reconstruction and classification

[[./images/cmn.png]]

[[https://www.nature.com/articles/s41467-019-10836-3][Learning cellular morphology with neural networks]]

This is Princeton work

Inference

Additionally, AWS Lambda -- The core technology
of serverless -- has mature in the interim such that large Python
codebases can now be deployed on Lambda. By adopting [[https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html][Lambda layers]] 3D
image recognition can be performed within a bossDB-based system, which
was not possible in 2015.

** High resolution billing 

- Cuboids aims to have multiple users from multiple organizations.
- Users can initially be anonymous but through Cognito become authenticated.
  - For the anonymous users, resource usage costs need to be assigned to the hosted dataset.
  - Authenticated users will be Reconstrue users, probably members of organizations 
  - Grafting on exist userbases is possible with Cognito. What about mapping that to billing?
- Fortunately, Lambda makes multi-tenancy easy [[https://narrativescience.com/resource/blog/how-aws-lambda-changed-the-game-of-multi-tenancy/][{1}]] [[https://techcrunch.com/2016/09/01/serverless-is-the-new-multitenancy/][{2}]]
   
* Open questions
- Will there still be a need for the Redis cache manager or will
  migrating to fully managed [[https://aws.amazon.com/elasticache/redis/fully-managed-redis/][Amazon ElastiCache for Redis]] remove the
  need for such
- How does bossDB deal with Redis? Is it fully managed?
  - Figure #7 seems to imply it is
- What to do about high-resolution billing so the costs can be billed
  to specific organizations and departments.
  - Since this in to be an all-in with AWS project the system should
    probably be instrumented for AWS Marketplace.
- Validate guesses about cross VPC communications speeds
- Perhaps bossDB can be reduced to a single repository containing a full
  CloudFormation stack which deploys everything needed. For example, the
  RESTful API machinery is currently in a separate repo but if migrated
  to Amazon API Gateway, can be reduced to a single module in the
  serverless repo. It would be neat and clean to be able to spin up a
  serverless spatial DB as single CloudFormation. Cuboids itself will
  probably be a separate CloudFormation. But it is to early to predict
  this. First active coding needs to proceed and then revisit this.

    
* Conclusion

It would be very valuable and desirable to not cause a fork in the
community but it would appear that such may be inevitable. Although the main thrust of
this proposal is simply an architectural refresh without significant changes to what the
software does, these changes touch just about every component what with the modification
of the auth system to Cognito. Nonetheless, a eye will be kept out for areas where interaction
can be maintained. For example, perhaps two bossDB deploys could interact. Both would be
on AWS so the data would not need to travel far. This could be how JHU/APL's deploy would
be the primary repository for the MICrONS data yet others could deploy applications which
interact via de facto standard (Boss) APIs.

The main the assumptions of this argument is that the data and code
will never leave AWS. So, Step Functions is the API to various
components. One component is like ChuckFlow but as a lambda. Chuckflow
would need to be extended work with TensorFlow. Sectarian arguments
about TensorFlow versus PyTorch and their ilk are interesting but a
political goal of Cuboids is to bring the work of Google Connectomics
into the mix. Unsurprisingly, their work is based on TensorFlow so
TensorFlow it is.


With regards to such potential experiments, they can be build upon the existing Lambdas.


Point is: go all-in with AWS. Yuch, but a realtechnik practicality, sadly, for now.

* License
  :PROPERTIES:
  :UNNUMBERED: notoc
  :END:
This document is licensed under [[https://creativecommons.org/publicdomain/zero/1.0/][the CC0 1.0 Universal (CC0 1.0) Public Domain Dedication]]

To the extent possible under law, John Tigue has waived all
copyright and related or neighboring rights to Cuboids Manifesto. This
work is published from: United States.

John Tigue has dedicated this work to the public domain by waiving all
of his or her rights to the work worldwide under copyright law,
including all related and neighboring rights, to the extent allowed by
law.

You can copy, modify, distribute and perform the work, even for
commercial purposes, all without asking permission.

* References
  :PROPERTIES:
  :UNNUMBERED: notoc
  :END:
- Cuboids repository
  - [ ] Code on GitHub.com: [[https://github.com/reconstrue/cuboids][reconstrue/cuboids]]
  - [ ] Website on GitHub.io;
  - License: [[https://github.com/reconstrue/cuboids/blob/master/LICENSE][Apache 2.0]]
- BossDB preprints
  - Hider, Kleissas, et alia, 2019
    - [[https://www.biorxiv.org/content/10.1101/217745v2][The Block Object Storage Service (bossDB): A Cloud-Native Approach for Petascale Neuroscience Discovery]]
    - doi: https://doi.org/10.1101/217745
  - Kleissas, Hider, et alia, 2017
    - [[https://www.biorxiv.org/content/10.1101/217745v1.abstract][The Block Object Storage Service (bossDB): A Cloud-Native Approach for Petascale Neuroscience Discovery]]
    - doi: https://doi.org/10.1101/217745
- Dean Kleissas talks
  - [[https://youtu.be/ldNqVmW9c98][AWS re:Invent 2017: The Boss: A Petascale Database for Large-Scale Neuroscience, Pow (DAT401)]]
  - [[https://www.youtube.com/watch?v=806a3x2s0CY][The Boss: A Petascale DB for Large-Scale Neuroscience Powered by Serverless Advanced Technologies]]
- Functional imaging montage assembled from:
  - [[https://www.researchgate.net/publication/47300810_Functional_imaging_of_hippocampal_place_cells_at_cellular_resolution_during_virtual_navigation][Functional imaging of hippocampal place cells at cellular resolution during virtual navigation]]
  - [[https://www.biorxiv.org/content/10.1101/459941v1.full][In vivo widefield calcium imaging of the mouse cortex for analysis of network connectivity in health and brain disease]]
  - [[https://www.cell.com/neuron/supplemental/S0896-6273(07)00614-9][Imaging Large-Scale Neural Activity with Cellular Resolution in Awake, Mobile Mice]]
  - [[https://www.sciencedirect.com/science/article/pii/S221112471631676X][Long-Term Optical Access to an Estimated One Million Neurons in the Live Mouse Cortex]]
  - [[https://www.phenosys.com/products/virtual-reality/jetball-tft/][JetBall-TFT]]
  - [[https://www.slideshare.net/InsideScientific/mobile-homecage-ssneurotar][Making Optical and Electrophysiological Measurements in the Brain of Head-Fixed, Freely-Moving Rodents]]
- Kool-Aid
  - The image in the introduction is a hacked up Marvel image, found via [[https://vsbattles.fandom.com/wiki/Kool-Aid_Man_(Marvel_Comics)][fandom.com]]
  - [[https://www.youtube.com/watch?v=_fjEViOF4JE][Kool-Aid Pitcher Man wall breaks]]
  - [[https://qz.com/74138/new-watered-down-kool-aid-man-just-wants-to-be-loved/][New, watered-down Kool-Aid Man just wants to be loved]]
- Mohammed and the Mountain cartoon
  - [[https://www.reddit.com/r/pics/comments/d07mf/look_gary_larson_put_mohammed_in_a_comic_and/][Far Side, Larson, 1992]]
